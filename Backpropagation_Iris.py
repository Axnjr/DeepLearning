# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1utIRQ1pOwe49hmKyi4NDxXw8OeNUlsqH
"""

import numpy as np
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

# Load the Iris dataset
iris = load_iris()
X = iris.data
y = pd.get_dummies(iris.target).values # One-hot encode labels

X
y

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,
random_state=42)
X_train, X_test, y_train, y_test

# Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

!pip install keras
import keras
from keras.models import Sequential
from keras.layers import Dense

# Build the DNN model
model = Sequential()
model.add(Dense(128, activation=keras.layers.LeakyReLU())) # Use LeakyReLU as an object
model.add(Dense(64, activation='relu'))
model.add(Dense(3, activation='softmax')) # 3 output classes for Iris

# Compile the model (assuming Adam was the best optimizer previously)
optimizer = Adam() # You can adjust learning rate etc. here
model.compile(loss='categorical_crossentropy', optimizer=optimizer,
metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test,
y_test))

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)
print(f"Test Loss: {loss}, Test Accuracy: {accuracy}")